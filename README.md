# 交通音频异常事件检测系统

这是一个基于深度学习的音频异常检测系统，采用两阶段训练策略，结合ATST-Frame模块和CRNN架构，可以自动识别音频中的异常事件。

## 项目结构

```
├── main.py                # 主入口脚本
├── requirements.txt       # 项目依赖
├── configs/               # 配置文件目录
│   └── config.yaml        # 模型配置文件
├── src/                   # 源代码目录
│   ├── trainer.py         # 模型训练脚本
│   └── inference.py       # 模型推理脚本
├── models/                # 模型定义目录
│   └── anomaly_detection_model.py  # 异常检测模型
├── utils/                 # 工具函数目录
│   └── data_processor.py  # 数据处理模块
├── data/                  # 数据存储目录
└── README.md              # 项目说明文档
```

## 系统组件

### 1. 数据预处理与特征提取
- **音频输入**：接受来自交通监控摄像头麦克风的单通道音频数据
- **特征提取**：从原始音频中提取梅尔频谱图（Mel-spectrogram）作为输入特征
- **数据增强**：支持添加背景噪声、时间偏移、速度调整、音量调整等数据增强技术

### 2. 模型架构
- **卷积神经网络（CNN）**：用于提取音频特征中的局部时频模式
- **循环神经网络（RNN）**：使用LSTM捕捉音频序列中的时间依赖性
- **自注意力机制**：增强模型对重要时刻的关注

### 3. 异常检测机制
- **重构误差**：通过比较输入与模型重构输出之间的误差来判断异常
- **阈值设定**：当重构误差超过设定阈值时，判定为异常事件

### 4. 训练与评估
- **训练策略**：使用正常音频数据进行训练，采用无监督学习方法
- **评估指标**：支持准确率、召回率、F1分数等评估指标

## 环境配置

### 安装依赖

```bash
pip install -r requirements.txt
```

### 数据集准备

### BCN Dataset预处理

项目包含专门的脚本用于处理BCN Dataset数据集，该数据集包含三段长音频和三个对应的数据标注。预处理步骤如下：

1. 确保已下载BCN Dataset数据集文件

2. 运行预处理脚本：
   ```bash
   python preprocess_bcn_data.py
   ```

3. 按照提示输入BCN Dataset文件所在的临时目录路径

4. 脚本将自动执行以下操作：
   - 创建符合模型要求的数据目录结构
   - 将长音频文件分割成5秒的短片段（可在config.yaml中配置）
   - 按照8:2的比例分割训练集和验证集
   - 将处理后的数据保存到`./data/BCNDataset`目录

处理完成后的数据目录结构如下：
```
./data/BCNDataset/
├── train/
│   ├── strong/     # 强标记训练数据
│   ├── weak/       # 弱标记训练数据（如果有）
│   └── unlabeled/  # 无标记训练数据（如果有）
└── val/
    ├── strong/     # 强标记验证数据
    ├── weak/       # 弱标记验证数据（如果有）
    └── unlabeled/  # 无标记验证数据（如果有）
```

### 配置文件设置

可以通过修改`configs/config.yaml`文件来自定义模型参数、训练参数和数据路径等配置。

## 使用指南

### 训练模型

运行主程序进行模型训练：
```bash
python main.py
```

训练过程将执行两阶段训练策略：
1. **第一阶段**：冻结ATST-Frame模块，训练CRNN部分，重点学习基础特征表示
2. **第二阶段**：解冻ATST-Frame模块，微调所有参数，并引入无监督学习，提高模型泛化能力

训练参数可以在`configs/config.yaml`文件中自定义，包括：
- 各阶段的学习率和训练轮数
- 批量大小和数据增强配置
- 优化器和正则化参数等

### 异常检测推理

处理单个音频文件：

```bash
python main.py infer --config configs/config.yaml --input /path/to/audio.wav --plot
```

处理目录中的所有音频文件：

```bash
python main.py infer --config configs/config.yaml --input /path/to/audio/directory --plot
```

### 命令行参数说明

- `--config`：配置文件路径（默认：configs/config.yaml）
- `--model`：训练好的模型路径（默认：使用配置文件中指定的路径）
- `--input`：输入音频文件或目录路径
- `--threshold`：异常检测阈值（默认：使用配置文件中指定的阈值）
- `--plot`：生成可视化结果（默认：不生成）

## 模型评估

模型训练和评估过程中使用的主要指标包括：

- **准确率（Accuracy）**：模型正确预测的样本比例
- **精确率（Precision）**：被预测为异常的样本中实际为异常的比例
- **召回率（Recall）**：实际为异常的样本中被正确预测的比例
- **F1分数（F1-Score）**：精确率和召回率的调和平均数
- **AUC-ROC曲线下面积**：评估模型区分正常和异常样本的能力
- **混淆矩阵可视化**：直观展示模型在不同类别上的表现

系统会自动生成并保存ROC曲线和混淆矩阵的可视化图表到`./plots/`目录。

## 注意事项

1. 确保您的环境中安装了所有必要的依赖包
2. 训练模型需要足够的计算资源，建议使用GPU加速
3. 为了获得最佳的异常检测效果，可能需要根据您的具体数据集调整阈值
4. 数据增强可以提高模型的鲁棒性，但也可能增加训练时间

## 扩展建议

1. 可以尝试不同的模型架构，如Transformer等
2. 考虑使用更多类型的数据增强技术
3. 探索半监督学习或迁移学习方法来提高检测性能
4. 可以开发实时检测系统，与交通监控系统集成